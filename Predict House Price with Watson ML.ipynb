{
    "metadata": {
        "language_info": {
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "file_extension": ".py", 
            "version": "2.7.11"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "# Predict house prices", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "**Original source:** https://medium.com/ibm-watson-data-lab/building-your-first-machine-learning-system-b3d9401927b7  \n**Modified by:** Jukka Ruponen /IBM, 2018-01-07", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "## Step 1: Identify what you want to predict and the source of your data", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "We\u2019ve identified that we want to predict house prices, and the data set we want to use to drive those predictions.\nThe data set available on GitHub:\n\nhttps://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv\n\nThis URL is going to be used to pull this data into our Notebook later on.", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "## Step 2: Import, clean and analyze the data", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "The next two cells below updates (optionally) and imports a Python library called PixieDust. PixieDust is an open source helper library that works as an add-on to Jupyter Notebooks that makes it easy to import and visualize data.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "#Optionally update the pixiedust to the latest version\n!pip install --user --upgrade pixiedust", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "import pixiedust", 
            "metadata": {}, 
            "execution_count": 3, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "Load the sample data from GitHub and create a data frame (df)", 
            "cell_type": "markdown"
        }, 
        {
            "source": "df = pixiedust.sampleData(\"https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv\")", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": 4, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Downloading 'https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv' from https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv\nDownloaded 92 bytes\nCreating pySpark DataFrame for 'https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv'. Please wait...\nLoading file using 'SparkSession'\nSuccessfully created pySpark DataFrame for 'https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv'\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "Next, we'll display the data.\nThis will generate a Spark DataFrame called \u201cdf\u201d. A DataFrame is a data set organized into named columns. You can think of it as a spreadsheet, or a relational database table. The Spark ML API uses DataFrames to train and test ML models.\n\nNote: This will display all of the data. If the data set was large, you should use head(df) instead)", 
            "cell_type": "markdown"
        }, 
        {
            "source": "display(df)", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "dataframe"
                    }
                }
            }, 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/html": "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div><style type=\"text/css\" class=\"pd_save is-viewer-good\">\n  .df-table-wrapper .panel-heading {\n    border-radius: 0;\n    padding: 0px;\n  }\n  .df-table-wrapper .panel-heading:hover {\n    border-color: #008571;\n  }\n  .df-table-wrapper .panel-title a {\n    background-color: #f9f9fb;\n    color: #333333;\n    display: block;\n    outline: none;\n    padding: 10px 15px;\n    text-decoration: none;\n  }\n  .df-table-wrapper .panel-title a:hover {\n    background-color: #337ab7;\n    border-color: #2e6da4;\n    color: #ffffff;\n    display: block;\n    padding: 10px 15px;\n    text-decoration: none;\n  }\n  .df-table-wrapper {\n    font-size: small;\n    font-weight: 300;\n    letter-spacing: 0.5px;\n    line-height: normal;\n    height: inherit;\n    overflow: auto;\n  }\n  .df-table-search-count {\n    display: inline-block;\n    margin: 20px 0;\n  }\n  .df-table-container {\n    max-height: 50vh;\n    max-width: 100%;\n    overflow-x: auto;\n    position: relative;\n  }\n  .df-table-wrapper table {\n    border: 0 none #ffffff;\n    border-collapse: collapse;\n    margin: 0;\n    min-width: 100%;\n    padding: 0;\n    table-layout: fixed;\n    height: inherit;\n    overflow: auto;\n  }\n  .df-table-wrapper tr.hidden {\n    display: none;\n  }\n  .df-table-wrapper tr:nth-child(even) {\n    background-color: #f9f9fb;\n  }\n  .df-table-wrapper tr.even {\n    background-color: #f9f9fb;\n  }\n  .df-table-wrapper tr.odd {\n    background-color: #ffffff;\n  }\n  .df-table-wrapper td + td {\n    border-left: 1px solid #e0e0e0;\n  }\n\n  .df-table-wrapper thead,\n  .fixed-header {\n    color: #337ab7;\n    font-family: monospace;\n  }\n  .df-table-wrapper tr,\n  .fixed-row {\n    border: 0 none #ffffff;\n    margin: 0;\n    padding: 0;\n  }\n  .df-table-wrapper th,\n  .df-table-wrapper td,\n  .fixed-cell {\n    border: 0 none #ffffff;\n    margin: 0;\n    min-width: 50px;\n    padding: 5px 20px 5px 10px;\n    text-align: left;\n    word-wrap: break-word;\n  }\n  .df-table-wrapper th {\n    padding-bottom: 0;\n    padding-top: 0;\n  }\n  .df-table-wrapper th div {\n    max-height: 1px;\n    visibility: hidden;\n  }\n\n  .df-schema-field {\n    margin-left: 10px;\n  }\n\n  .fixed-header-container {\n    overflow: hidden;\n    position: relative;\n  }\n  .fixed-header {\n    border-bottom: 2px solid #2e6da4;\n    display: table;\n    position: relative;\n  }\n  .fixed-row {\n    display: table-row;\n  }\n  .fixed-cell {\n    display: table-cell;\n  }\n</style><div class=\"df-table-wrapper df-table-wrapper-1298ff92 panel-group pd_save is-viewer-good\">\n  <!-- dataframe schema -->\n  \n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\" style=\"margin: 0px;\">\n        <a data-toggle=\"collapse\" href=\"#df-schema-1298ff92\" data-parent=\"#df-table-wrapper-1298ff92\">Schema</a>\n      </h4>\n    </div>\n    <div id=\"df-schema-1298ff92\" class=\"panel-collapse collapse\">\n      <div class=\"panel-body\" style=\"font-family: monospace;\">\n        <div class=\"df-schema-type\">\n          <span>type: </span><span>struct</span>\n        </div>\n        <div class=\"df-schema-fields\">\n          <div>field:</div>\n          \n            <div class=\"df-schema-field\">{'metadata': {}, 'type': 'integer', 'name': 'SquareFeet', 'nullable': True}</div>\n          \n            <div class=\"df-schema-field\">{'metadata': {}, 'type': 'integer', 'name': 'Bedrooms', 'nullable': True}</div>\n          \n            <div class=\"df-schema-field\">{'metadata': {}, 'type': 'string', 'name': 'Color', 'nullable': True}</div>\n          \n            <div class=\"df-schema-field\">{'metadata': {}, 'type': 'integer', 'name': 'Price', 'nullable': True}</div>\n          \n        </div>\n      </div>\n    </div>\n  </div>\n  \n  <!-- dataframe table -->\n  <div class=\"panel panel-default\">\n    \n    <div class=\"panel-heading\">\n      <h4 class=\"panel-title\" style=\"margin: 0px;\">\n        <a data-toggle=\"collapse\" href=\"#df-table-1298ff92\" data-parent=\"#df-table-wrapper-1298ff92\">Table</a>\n      </h4>\n    </div>\n    \n    <div id=\"df-table-1298ff92\" class=\"panel-collapse collapse in\">\n      <div class=\"panel-body\">\n        \n        <input class=\"df-table-search form-control input-sm\" placeholder=\"Search table\" type=\"text\">\n        <div>\n          <span class=\"df-table-search-count\">Showing 3 of 3</span>\n        </div>\n        <!-- fixed header for when dataframe table scrolls -->\n        <div class=\"fixed-header-container\">\n          <div class=\"fixed-header\">\n            <div class=\"fixed-row\">\n              \n              \n              <div class=\"fixed-cell\">SquareFeet</div>\n              \n              \n              \n              <div class=\"fixed-cell\">Bedrooms</div>\n              \n              \n              \n              <div class=\"fixed-cell\">Color</div>\n              \n              \n              \n              <div class=\"fixed-cell\">Price</div>\n              \n              \n            </div>\n          </div>\n        </div>\n        <div class=\"df-table-container\">\n          <table class=\"df-table\">\n            <thead>\n              <tr>\n                \n                \n                <th><div>SquareFeet</div></th>\n                \n                \n                \n                <th><div>Bedrooms</div></th>\n                \n                \n                \n                <th><div>Color</div></th>\n                \n                \n                \n                <th><div>Price</div></th>\n                \n                \n              </tr>\n            </thead>\n            <tbody>\n              \n              <tr>\n                \n                \n                <td>2100</td>\n                \n                \n                \n                <td>3</td>\n                \n                \n                \n                <td>White</td>\n                \n                \n                \n                <td>100000</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2300</td>\n                \n                \n                \n                <td>4</td>\n                \n                \n                \n                <td>White</td>\n                \n                \n                \n                <td>125000</td>\n                \n                \n              </tr>\n              \n              <tr>\n                \n                \n                <td>2500</td>\n                \n                \n                \n                <td>4</td>\n                \n                \n                \n                <td>Brown</td>\n                \n                \n                \n                <td>150000</td>\n                \n                \n              </tr>\n              \n            </tbody>\n          </table>\n        </div>\n      </div>\n    </div>\n  </div>\n</div><script class=\"pd_save is-viewer-good\">\n  $(function() {\n    var tableWrapper = $('.df-table-wrapper-1298ff92');\n    var fixedHeader = $('.fixed-header', tableWrapper);\n    var tableContainer = $('.df-table-container', tableWrapper);\n    var table = $('.df-table', tableContainer);\n    var rows = $('tbody > tr', table);\n    var total = 3;\n\n    fixedHeader\n      .css('width', table.width())\n      .find('.fixed-cell')\n      .each(function(i, e) {\n        $(this).css('width', $('.df-table-wrapper-1298ff92 th:nth-child(' + (i+1) + ')').css('width'));\n      });\n\n    tableContainer.scroll(function() {\n      fixedHeader.css({ left: table.position().left });\n    });\n\n    rows.on(\"click\", function(e){\n        var txt = e.delegateTarget.innerText;\n        var splits = txt.split(\"\\t\");\n        var len = splits.length;\n        var hdrs = $(fixedHeader).find(\".fixed-cell\");\n        // Add all cells in the selected row as a map to be consumed by the target as needed\n        var payload = {type:\"select\", targetDivId: \"\" };\n        for (var i = 0; i < len; i++) {\n          payload[hdrs[i].innerHTML] = splits[i];\n        }\n\n        //simple selection highlighting, client adds \"selected\" class\n        $(this).addClass(\"selected\").siblings().removeClass(\"selected\");\n        $(document).trigger('pd_event', payload);\n    });\n\n    $('.df-table-search', tableWrapper).keyup(function() {\n      var val = '^(?=.*\\\\b' + $.trim($(this).val()).split(/\\s+/).join('\\\\b)(?=.*\\\\b') + ').*$';\n      var reg = RegExp(val, 'i');\n      var index = 0;\n      \n      rows.each(function(i, e) {\n        if (!reg.test($(this).text().replace(/\\s+/g, ' '))) {\n          $(this).attr('class', 'hidden');\n        }\n        else {\n          $(this).attr('class', (++index % 2 == 0 ? 'even' : 'odd'));\n        }\n      });\n\n      $('.df-table-search-count', tableWrapper).html('Showing ' + index + ' of ' + total);\n    });\n  });\n\n  $(\".df-table-wrapper td:contains('http://')\").each(function(){var tc = this.textContent; $(this).wrapInner(\"<a target='_blank' href='\" + tc + \"'></a>\");});\n  $(\".df-table-wrapper td:contains('https://')\").each(function(){var tc = this.textContent; $(this).wrapInner(\"<a target='_blank' href='\" + tc + \"'></a>\");});\n</script>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}, 
                    "output_type": "display_data"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "## Step 3: Use Apache Spark ML to build and test a machine learning model\nWe\u2019re going to build our first ML model in just a handful of cells. To start we need to import the Spark ML libraries that we\u2019ll be using:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler", 
            "metadata": {}, 
            "execution_count": 7, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "Our goal is a regression problem (we\u2019re trying to predict a real number), so we are going to use the Linear Regression algorithm in pyspark.ml.regression. There are other regression algorithms, but those are outside of the scope of this post.\n\nWe are going to build our ML model in just four lines of code, all in a single cell in our notebook:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "# Defining the ML model (linear regression)\n\n# Our ML algorithm expects a single vector of feature columns.\n# So here we use a VectorAssembler to tell our ML pipeline that we want SquareFeet and Bedrooms as our features:\nassembler = VectorAssembler(inputCols=['SquareFeet','Bedrooms'],outputCol=\"features\")\n\n# Next, we create an instance of LinearRegression, the ML algorithm we are going to use.\n# At a minimum, you must specify the features and the labels.\n# There are other parameters you can provide to tweak the algorithm, but they\u2019re not going to do us much good when working with three data points :)\nlr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, labelCol='Price', featuresCol='features')\n\n# Next, we create our pipeline.\n# A Pipeline allows us to specify the steps that should be performed when training an ML model.\n# In this case, we first want to assemble our two feature columns into a single vector\u200a\u2014\u200athat\u2019s the assembler.\n# Then we want to run it through our LinearRegression algorithm (lr).\npipeline = Pipeline(stages=[assembler, lr])\n\n# Finally, we pass our DataFrame to the fit method on the pipeline to create our ML model.\nmodel = pipeline.fit(df)", 
            "metadata": {}, 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "**Test the model**  \nIt\u2019s time to test our model. We are next going to run a single prediction.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "# Defining a Python function to get our prediction (creates the DataFrame we\u2019ll pass to our model):\ndef get_prediction(square_feet, num_bedrooms):\n    df_req = spark.createDataFrame([(square_feet, num_bedrooms)],\n                                   ['SquareFeet','Bedrooms'])\n    df_res = model.transform(df_req)\n    return df_res", 
            "metadata": {}, 
            "execution_count": 12, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Run the test prediction with 2400 sq-feet and 4 bedrooms:\nres = get_prediction(2400, 4)\nres.show()", 
            "metadata": {}, 
            "execution_count": 17, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+----------+--------+------------+------------------+\n|SquareFeet|Bedrooms|    features|        prediction|\n+----------+--------+------------+------------------+\n|      2400|       4|[2400.0,4.0]|137499.79216713924|\n+----------+--------+------------+------------------+\n\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "## Step 4: Save & Deploy model to Watson ML service", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "Let's first import some libraries that we'll need:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "import json\nimport requests\nimport urllib3", 
            "metadata": {}, 
            "execution_count": 18, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "In this Notebook we\u2019ve now trained and tested our machine learning model, but if we want to predict house prices from a web or mobile app it\u2019s not going to do us much good in this notebook. That\u2019s where Watson ML service comes in.\n\nIn this notebook, we\u2019re next going to deploy this model to Waston ML and create a \u201cscoring endpoint\u201d, or a REST API for making predictions.\n\nThe first thing you\u2019ll need to do next is specify your Watson ML credentials in  this Notebook.\nIf you do not yet have the Watson ML service created, do the following steps:\n1. In another browser window, go to https://console.bluemix.net/catalog/services/machine-learning and create a **Watson Machine Learning** service instance  \n**Note**: For your convenience, you should create the Watson ML service in the same space than your Spark service instance\n2. Check your Watson ML credentials from bluemix console by opening the just created Watson ML service and clicking \"Service Credentials\" on the left\n3. If you do not yet have any credentials provisioned, press \"Create credentials\" and \"Add\". Then check your credentials again (step 2).\n4. Copy your unique credential values (username, password and instance_id) to the cell below:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "# Watson ML credentials:\nservice_path = 'https://ibm-watson-ml.mybluemix.net'\nusername = 'YOUR_WML_USER_NAME'\npassword = 'YOUR_WML_PASSWORD'\ninstance_id = 'YOUR_WML_INSTANCE_ID'\nmodel_name = 'House Prices Model'\ndeployment_name = 'House Prices Deployment'", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "The next two cells initializes some libraries for connecting to Watson ML. These libraries are built into DSX:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact", 
            "metadata": {}, 
            "execution_count": 20, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)\nml_model_name = model_name", 
            "metadata": {}, 
            "execution_count": 52, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "Create model artifact (abstraction layer)", 
            "cell_type": "markdown"
        }, 
        {
            "source": "pipeline_artifact = MLRepositoryArtifact(pipeline, name=\"pipeline\")", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "**Saving the model to Watson ML**  \nNext, we\u2019ll use these libraries to save our model to Watson ML. We pass the trained model, our data set, and a name for the model\u200a\u2014\u200ain this case we\u2019re calling it \u201cHouse Prices Model\u201d:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "model_artifact = MLRepositoryArtifact(model, training_data=df, name=ml_model_name, pipeline_artifact=pipeline_artifact)\nsaved_model = ml_repository_client.models.save(model_artifact)\nsaved_model", 
            "metadata": {}, 
            "execution_count": 53, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "<repository.mlrepositoryclient.model_adapter.ModelArtifact at 0x7f083d353bd0>"
                    }, 
                    "metadata": {}, 
                    "execution_count": 53, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "To confirm that our model was saved in Watson ML, list all models that comply to our model name:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "ml_model_name = 'House Prices Model'\nml_models = ml_repository_client.models.all()\nfor ml_model in ml_models:\n    print '{} - {}'.format(ml_model.name, ml_model.uid)", 
            "metadata": {}, 
            "execution_count": 54, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "House Prices Model - 3989a65c-c3bb-4012-aeb4-91667804cbe9\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "**Request an id, pointing to our saved Watson ML model**  \nThe call to models.save above returned an **object** that we stored in **saved_model** variable, from which we extracted the unique ID for the model, mode_id. This **model_id** is important as it will be used later to create a deployment for the model.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "model_id = saved_model.uid\nmodel_id", 
            "metadata": {}, 
            "execution_count": 55, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "'3989a65c-c3bb-4012-aeb4-91667804cbe9'"
                    }, 
                    "metadata": {}, 
                    "execution_count": 55, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "**Preparing to deploy the model in Watson ML**  \nWe are now going to create a Deployment for our ML model. In other words, we are going to deploy a running instance of our model. To do this, we'll use the Watson ML REST API. The Watson ML REST API uses token-based authentication, so our first step is to generate a token using our Watson ML credentials:", 
            "cell_type": "markdown"
        }, 
        {
            "source": "# Generate access token for Watson ML REST API\nheaders = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\nurl = '{}/v3/identity/token'.format(service_path)\nresponse = requests.get(url, headers=headers)\nml_token = 'Bearer ' + json.loads(response.text).get('token')", 
            "metadata": {}, 
            "execution_count": 56, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Display the access token for Watson ML REST API:\nml_token", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "# Get our model in Watson ML via REST api\nmodel_url = service_path + \"/v3/wml_instances/\" + instance_id\nmodel_header = {'Content-Type': 'application/json', 'Authorization': ml_token}\nmodel_response = requests.get(model_url, headers=model_header)\nprint model_response.text", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "**Model Deployment**  \nNow we can actually create our deployment. Here we make an HTTP POST to the published_models/deployments endpoint\u200a\u2014\u200apassing in our Watson ML instance_id and the model_id of our newly saved model.", 
            "cell_type": "markdown"
        }, 
        {
            "source": "deployment_url = service_path + \"/v3/wml_instances/\" + instance_id + \"/published_models/\" + model_id + \"/deployments/\"\ndeployment_header = {'Content-Type': 'application/json', 'Authorization': ml_token}\ndeployment_payload = {\"type\": \"online\", \"name\": deployment_name}\ndeployment_response = requests.post(deployment_url, json=deployment_payload, headers=deployment_header)\nprint deployment_response\nprint deployment_response.text", 
            "metadata": {}, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "**OPTIONAL:**  \nRun the cell below **ONLY** if you want to delete any previously existing Watson ML deployments!  \nThis may be useful to clean up things but **BE WARNED, IT IS DESTRUCTIVE!**  \nOtherwise, just skip it and DO NOT RUN IT!", 
            "cell_type": "markdown"
        }, 
        {
            "source": "## WARNING - THIS CELL WILL DELETE ANY SAVED MODELS AND DEPLOYMENTS THAT ALREADY EXIST!\n## DO NOT RUN THIS AND SKIP IT, UNLESS THIS IS EXACTLY WHAT YOU WANT TO DO!\n\nfor ml_model in ml_models:\n    print '{} - {}'.format(ml_model.name, ml_model.uid)\n    deployment_header = {'Content-Type': 'application/json', 'Authorization': ml_token}\n    deployment_url = service_path + \"/v2/published_models/\" + ml_model.uid + \"/deployments/\"\n    deployment_response = requests.get(deployment_url, headers=deployment_header)\n    o = json.loads(deployment_response.text)\n    if 'resources' in o.keys():\n        for resource in o['resources']:\n            deployment_url = service_path + \"/v2/published_models/\" + ml_model.uid + \"/deployments/\" + resource['metadata']['guid']\n            deployment_response = requests.delete(deployment_url, headers=deployment_header)\n            print deployment_response.text\n        # delete the model\n        ml_repository_client.models.remove(ml_model.uid)", 
            "metadata": {}, 
            "execution_count": 51, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "## Step 5: Test the model in Watson ML service", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "**Get the HTTP endpoint URL to access our model**  \nThe last line below prints the scoring_url parsed from the response received from Watson ML. This is an **HTTP endpoint** that we can use to make predictions. You now have a deployed machine learning model that you can use to predict house prices from anywhere! You can call it from a front-end application, your middleware, or from a notebook\u200a\u2014\u200awe\u2019ll do just that next :)", 
            "cell_type": "markdown"
        }, 
        {
            "source": "scoring_url = json.loads(deployment_response.text).get('entity').get('scoring_url')\nprint scoring_url", 
            "metadata": {}, 
            "execution_count": 60, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "https://ibm-watson-ml.mybluemix.net/v3/wml_instances/ce16a175-2a90-4725-b08a-ded2dd5fbee9/published_models/3989a65c-c3bb-4012-aeb4-91667804cbe9/deployments/31b99366-7ce9-466d-8e0b-72be805f8931/online\n"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "**Test the model via HTTP**", 
            "cell_type": "markdown"
        }, 
        {
            "source": "# Define the HTTP POST request to scoring_url\ndef get_prediction_from_watson_ml(square_feet, num_bedrooms):\n    scoring_header = {'Content-Type': 'application/json', 'Authorization': ml_token}\n    scoring_payload = {'fields': ['SquareFeet','Bedrooms'], 'values': [[square_feet, num_bedrooms]]}\n    print scoring_payload\n    scoring_response = requests.post(scoring_url, json=scoring_payload, headers=scoring_header)\n    return scoring_response.text\n    #values = json.loads(scoring_response.text)['values'][0]\n    #prediction = values[len(values)-1]\n    #return {'prediction': prediction, 'probability': values[len(values)-2][int(prediction)]}", 
            "metadata": {}, 
            "execution_count": 61, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "response = get_prediction_from_watson_ml(2400, 4)\nprint response", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": 62, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "{'fields': ['SquareFeet', 'Bedrooms'], 'values': [[2400, 4]]}\n{\n  \"fields\": [\"SquareFeet\", \"Bedrooms\", \"features\", \"prediction\"],\n  \"values\": [[2400, 4, [2400.0, 4.0], 137499.79216713924]]\n}\n"
                }
            ]
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "## Next steps", 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "In this post you built an end-to-end machine learning system using the IBM Data Science Experience, Spark ML, and Watson ML.\n\nIn just a few lines of code, you imported and visualized a data set.  \nThen you built an ML pipeline and trained an ML model.  \nFinally you made that model available in Watson ML service to make predictions from software running anywhere.\n\nIf you wish, you can now proceed to create a simple application that takes \"house size\" and \"number of bedrooms\" as inputs, then calls your Watson ML model and displays predicted price for it.\nCheck out this the GitHub repo for simple Node-RED example: https://github.com/jruponen/watson_ml_with_wdp\n", 
            "cell_type": "markdown"
        }
    ], 
    "nbformat_minor": 1
}